\subsection{Algorithm Description}
This part of the report gives a detailed description of the Dantzig Wolfe Decomposition \cite{dantzig1960decomposition} in solving the LP of block angular form. The notations are used solely in this part of the report.

Consider a linear program of the form
\begin{equation}
\begin{split}
            \min_x &\quad c^\top x\\
    {\rm s.t.}&\quad Ax\leq b, \quad x\geq 0
\end{split}
\end{equation}

We can define the constraint matrix is of the form
\begin{equation}
    A=\left[
    \begin{matrix}
    L_1&L_2&\cdots&L_K\\
    A_1& & &\\
    & A_2&&\vdots\\
    &&\ddots &\\
    &&&A_K\\
    \end{matrix}
    \right]
\end{equation}

Such a form for $A$ is called block angular, and the linear system is defined by
\begin{equation}
\label{eq:dantzig_origin}
\begin{split}
        \min\quad  \sum_{k=1}^K (c^k)^\top & x^k\\
    {\rm s.t.} \quad \sum_{k=1}^L L_k x^k&\leq b^0\\
    A_k x^k &\leq b^k\quad k=1,2,\cdots,K\\
    x^k&\geq 0\quad k=1,2,\cdots,K
\end{split}
\end{equation}

It is not enough to have the decomposition into master and subproblems as
above. To make the decomposition effective, the master problem needs reformulation. The reformulation will enable the master problem and subproblems
to exchange information regarding progress toward an optimal solution for the
original linear program while enabling each problem to be solved separately.
The key to reformulation is the fact that the subproblems are all linear pro-
grams and so the feasible sets are polyhedrons.

Let $P_k=\{x^k|A_k x^k\leq b^k\}$ be the extreme feasible sets of the constraints and $v_1^k,v_2^k,\cdots,v_{N_k}^k$ be the extreme points of $P_k$ and $d_1^k,d_2^k,\cdots,d_{l_k}^k$ be the extreme directions of Pk. Then, any point $x^k\in P_k$ can be expressed as
\begin{equation}
    x^k=\sum_{i=1}^{N_k} \lambda_i^k v_i^k+\sum_{j=1}^{l_k} \mu_j d_j^k
\end{equation}
where $\sum_{i=1}^{N_k} \lambda_i^k=1,\lambda_i^k\geq 0,\mu_j^k\geq 0$. 

The the Dantzig-Wolfe decomposition of the original LP is (\ref{eq:dantzig_origin}) is
\begin{equation}
\label{eq:dantzig_decomp}
\begin{split}
    \min &\quad \sum_{i=1}^{N_k} \lambda_i^k p_i^k +\sum_{j=1}^{l_k} \mu_j^k \bar{p}_j^k\\
    \text{s.t.}&\quad \sum_{k=1}^K (\sum_{i=1}^{N_k} \lambda_i^k q_i^k +\sum_{j=1}^{l_k} \mu_j^k \bar{q}_j^k)\leq b^0\\
    &\quad \sum_{i=1}^{N_k}\lambda_i^k = 1\\
    &\quad \lambda_i^k,\mu_j^k\geq 0
\end{split}
\end{equation}
where $p_i=(c^k)^\top v_i^k, \bar{p}_j^k=(c^k)^\top d_j^k, q_i^k=L_kv_i^k$ and $\bar{q}_j^k=L_k d_j^k$. The constraint $\sum_{k=1}^K (\sum_{i=1}^{N_k} \lambda_i^k q_i^k +\sum_{j=1}^{l_k} \mu_j^k \bar{q}_j^k)$ is called the linking constraint, with dual variable denoted as $\pi^1$, and $K$ constraint $\sum_{i=1}^{N_k}\lambda_i^k = 1$ are called convexity constraint, with dual variable denoted as $\pi^2_k$.

\subsection{Column Generation on the Dantzig Wolfe Decomposition}

The number of variables $\lambda_i^k$ and $\mu_j^k$ can be extremely large for even moderately sized problems since feasible sets of subproblems (linear programs) can have an extremely large number of extreme points and extreme directions. In other words, there will be many more columns than rows in the reformulated master problem. 

Actually, the node-arc formulation of the classical multicommodity problem corresponds to an LP with the block angular form in (\ref{eq:dantzig_origin}). After the reformulation, it has been shown that it is equivalent to the path-based formulation of the multicommodity problem. Since our problem has been path-based, the above procedures are not necessary. We will focus on the following procedures of the Dantzig-Wolfe decomposition, in other words, the column generation methods. 

The key idea to get around this difficulty of handling an extremely large number of variables is to use the revised simplex method to solve the master problem. The major advantage is that it is not necessary to formulate the
entire reformulated master problem since the vast majority of the variables
will be zero (i.e., non-basic) at an optimal (basic feasible) solution. This motivates the construction of a smaller version of the master problem
called the restricted master problem where only a small subset of the variables $\lambda_i^k$ and $\mu_j^k$ included corresponding to a current basic feasible solution, and the remaining variables are non-basic, i.e., set to zero. If the reduced costs of the basic feasible solution are non-negative, then the revised simplex method stops with the optimal solution, else some non-basic variable with negative reduced cost is selected to enter the basis.

Given a current basis $B$ for the restricted master problem, solve the liear system $B^\top \pi = q_B$, where $q_B$ is a vector consisting of the quantities $q_i^k$ and $\bar{q}_i^k$ associated with variables $\lambda_i^k$ and $\mu_j^k$, which are basic. 

We assume that the components of $\pi$ are arranged so that $\pi^\top = [(\pi^1)^\top, \pi^2_1,\cdots,\pi_K^2]$. Then the reduced cost corresponding to a non-basic variable $\lambda_i^k$ is of the form
\begin{equation}
    r_i^k = p_i^k- \pi^\top \left[\begin{matrix}
    q_i^k\\e_k
    \end{matrix}\right]
\end{equation}
and the reduced cost for corresponding to a non-basic variable $\mu^k_j$ is of the form
\begin{equation}
    \bar{r}_j^l=\bar{p}_j^k-\pi^\top \left[\begin{matrix}
    \bar{q}_i^k\\0
    \end{matrix}\right]
\end{equation}
the main difference comes from the convexity constraint. 

Since we want to minimize all the $r_i^k$,  we have
\begin{equation}
    r_{\min}=\min_k \left\{
    \min_i (c^k)^\top v_i^k - (\pi^1)^\top L_k v_i^k -\pi_k^2
    \right\}
\end{equation}

Let $r_\star^k=\min_i {r_i^k}$, where $r_i^k$ is equivalent to the optimal objective function of the subproblem
\begin{equation}
\label{eq:dantzig_subproblem}
\begin{split}
        \min&\quad ((c^k)^\top -(\pi^1)^\top L_k)x^k-\pi^2_k\\
        \text{s.t.}&\quad A_k x^k \leq b^k,\quad x^k\geq 0
\end{split}
\end{equation}
since $v_i^k$s are the extreme points of the polygon $A_kx^k\leq b^k$.  

There are three possibilities in solving the subproblems in attempting
to generate $r_{\min}$.
\begin{enumerate}
    \item If all subproblems are bounded and $r_{\min}<0$, then let $t$ be the index of minimal value. The column associated with the optimal extreme point $\lambda_i^t$ is added into the basis $B$.
    \item If all subproblems are bounded and $r_{\min}\geq 0$, then the current basis $B$ is optimal.
    \item If there is at least one subproblem that is unbounded, then let $s$ be the index $k$ of such an unbounded subproblem. The revised simplex method will return an extreme direction $d_j^s$ associated with the subproblem such that $((c^s)^\top -(\pi^1)^\top L_s)d_j^s<0$ and so the column associated with $\mu_j^s$ can enter the basis $B$.
\end{enumerate}

% We give a summary of the Dantzig-Wolfe Decomposition Method
% \begin{enumerate}
%     \item {\bf Initialization}: Generate an initial basis $B$ for the master problem. Let $x_B$ be the basic variables and $B$ the index set of the basic variables and set all other variables to non-basic (zero) to get the restricted master problem. Go to Step 1.
%     \item {\bf Simplex Multiplier Generation}: Solve for $\pi $ in the linear system $B^\top \pi=p_B$. Go to Step 2.
%     \item {\bf Optimality Check}: Solve the subproblems (\ref{eq:dantzig_subproblem}) for $k=1,2,\cdots,K$. If the subproblem $k$ is unbounded, then go to Step 3, else let $x_k = v^k_{i^\star}$ denote the optimal basic feasible solution. If $r_{\min} = \min_{k} \{r_{\star}^k\}$, then the current basis is optimal, {\bf stop}, else go to Step 3.
%     \item {\bf Column Generation}: If all subproblems SPk are bounded and $r_{\min}<0$, then let $t$ be the index $t$ such that $r_{\min}=r_\star^t$. Let $\bar{a}=\left[\begin{matrix}L_t v^t_{i^\star}\\e_t\end{matrix} 
%     \right]$, where $v^t_{i^\star}$ is is the optimal extreme point of the $t$-th subproblem and go to Step 4.
    
% \end{enumerate}

\subsection{Application to the Muticommodity Problem}
In this part, we focus on applying the Dantzig-Wolfe decomposition to our multicommodity problem. The notations are adopted from Section (\ref{sec:definition}).

For the master problem \ref{eq:origin}, we introduce the dual variable $\pi^1\geq 0$ for (\ref{eq:2b}), $\sigma_k, 1\leq k \leq K$ for (\ref{eq:2c}), and $u$ for the equation \ref{eq:2d}. We can write the Lagrangian to be
\begin{equation}
L(\x,t,\pi,\sigma,u)=t+\pi^\top (\R \x-ct) + \sum_{k=1}^K \sigma_k(d_k-1^\top x_k)+u(t-1)
\end{equation}

Hence, the dual problem can be written as (deleting $u$)
\begin{equation}
\begin{split}
        \min_{\pi,\sigma}&\quad c^\top \pi-\sigma^\top d\\
        \text{s.t.}&\quad R_k^\top \pi \geq \sigma_k1\\
        &\quad c^\top \pi \geq 1\\
        &\quad \pi \geq 0 
\end{split}
\end{equation}
% and the complementary slackness condition can be written as
% \begin{equation}
%     \begin{split}
%         \pi_l^\star (\R[l] \x^\star-c_lt^\star)&=0\\
%     \end{split}
% \end{equation}


For the Master Problem (\ref{eq:origin}), we first solves a Restricted Master Problem: 
\begin{subequations}
\begin{align}
\min _{\mathbf{x},t} \quad & t \\
\text {s.t.} \quad& \mathbf{R_B x} \leq \mathbf{c}t\label{eq:RMPb} \\
& 1^\top \mathbf{x}_{k}=d_{k} \label{eq:RMPc} \\
& t\leq 1 \label{eq:RMPd}\\
& \mathbf{x} \geq 0
\end{align}
\end{subequations}
where $\mathbf{B}$ is a subset of all columns (paths) of $\R$, and generate the corresponding dual variable. Then, we aim to verify whether the all the dual  constraints are satisfied, which are of huge amount. Hence, we might formulate it as a pricing problem. 

Since $\R$ encode the information of the path and the link, we will decompose the relation in the following. For the commodity $k$, and any path $p_k\in P(k)$, we want to verify whether $(R_k^p)^\top \pi \geq \sigma_k$ holds. In other words, whether $\min_{p_k} -\sigma_k+\sum_l R_{l,p_k}^k \pi_l\geq 0$.

If we denote the link $l$ as link $(i,j)$, where $i,j$ represent the nodes. Any path $p_k$ must obeys the relation:
\begin{equation}
\sum_{(i,j)\in \mathcal{E}} R_{(i,j),p}^k - \sum_{(j,i)\in \mathcal{E}} R_{(j,i),p}^k = \alpha_i^k.
\end{equation}
where $\alpha_i^k$ equals 1 if $i$ is the starting node of the commodity $k$, equals $-1$ if i is the
destination of $k$ and $0$ otherwise. 

Finally, we can rewrite the pricing problem as Integer Programs. For each commodity $k$, we solve the following integer program:
\begin{equation}
    \begin{split}
    \min_{R}&\quad -\sigma_k+\sum_l R_{l,p}^k \pi_l\\
    {\rm s.t.}&\quad \sum_{(i,j)\in \mathcal{E}} R_{(i,j),p}^k - \sum_{(j,i)\in \mathcal{E}} R_{(j,i),p}^k = \alpha_i^k\\
    &\quad R_{l,p}^k  \in \{0,1\}
    \end{split}
\end{equation}

Indeed if the objective function value of the optimal solution is negative, then it implies that the path $p$ obtained via solving the Integer Problem violates a constraints in the dual of the Master Problem. This integer problem can also be solved by the famous Dijkstra’s algorithm. We need only regard $\pi_l$ as cost on each edge.